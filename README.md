# ğŸ§ Emotion-Driven Music Recommendation System

A deep learning-based system that detects emotions from facial images using a fine-tuned **ResNet50V2** model and recommends music accordingly. This project was developed as part of our final year B.Tech project in Artificial Intelligence and Data Science.

---

## ğŸ§  Project Overview

- ğŸ§‘â€ğŸ¤– Uses facial expression recognition to detect emotions
- ğŸµ Maps detected emotion to a music category (e.g., Pop, Acoustic, Metal)
- ğŸ§¬ Model built using **Transfer Learning (ResNet50V2)**
- ğŸ’» Trained and tested using **FER-2013 dataset**
- ğŸ“‚ Includes academic submission files, proof documents, and visuals

---

## ğŸ“ Repository Structure

- `base documents/` â€“ Reference research papers (6â€“7 used for literature review)
- `paper and ppt/` â€“ Final research paper (IEEE format), project PPT, and summary report
- `proof/` â€“ Turnitin plagiarism report, conference certificate, and email confirmation
- `report/` â€“ Full project report broken into multiple PDFs (7â€“8 chapters)
- `required images/` â€“ All visuals used in the paper, PPT, and report
- `src/` â€“ Python source code and dataset
  - `emotion-based-music-recommender-resnet50v2.ipynb` â€“ Jupyter notebook with model and recommendation system
- `README.md` â€“ This documentation file


## ğŸ§ª Model Details

- Model: **ResNet50V2** (Transfer Learning)
- Framework: **TensorFlow / Keras**
- Dataset: **FER-2013** (7 emotion classes)
- Preprocessing: Image resizing, normalization
- Output: Predicted emotion mapped to a music recommendation

---

## ğŸ­ Emotion Classes

- Happy
- Sad
- Angry
- Disgust
- Fear
- Surprise
- Neutral

---

## ğŸµ Emotion-to-Music Mapping

| Emotion  | Recommended Music Style      |
|----------|------------------------------|
| Happy    | Pop, Dance, Indie            |
| Sad      | Acoustic, Piano              |
| Angry    | Rap, Rock, Metal             |
| Neutral  | Chill, Lo-Fi, Instrumental   |
| Fear     | Calm, Nature Sounds          |
| Surprise | Electronic, Cinematic        |
| Disgust  | Ambient, Soothing tunes      |

---

## ğŸš€ How to Run the Project

1. Navigate to the `src/` folder
2. Open the Jupyter Notebook:  
   `emotion-based-music-recommender-resnet50v2.ipynb`
3. Install required dependencies:
   ```bash
   pip install tensorflow opencv-python matplotlib
4. Run the notebook cells to:

- âœ… Load the model
- âœ… Predict emotion from an image
- âœ… Display mapped music suggestion


## ğŸ› ï¸ Tools & Libraries

- Python
- TensorFlow / Keras
- OpenCV
- Matplotlib
- NumPy
- Pandas


## ğŸ“š Academic Submission Includes

- âœ”ï¸ Final research paper (IEEE format)
- âœ”ï¸ Final PPT and mini-report
- âœ”ï¸ Chapter-wise full report
- âœ”ï¸ Turnitin proof and conference participation
- âœ”ï¸ Referenced base papers


## ğŸ™Œ Contributors

- **Gopikashree PR** â€“ B.Tech Artificial Intelligence & Data Science  


## ğŸ“¬ Contact

**Gopikashree PR**  
[GitHub](https://github.com/gopikashreepr)  
[LinkedIn](https://www.linkedin.com/in/gopikashree-pr/)  
[Email](mailto:gopikassakipog@gmail.com)

